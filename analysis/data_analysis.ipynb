{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "from functions import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/survey_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count unique user_ids\n",
    "print(f'Unique user_ids: {data.user_id.nunique()}\\n')\n",
    "\n",
    "# get average size of each group\n",
    "print(f'Average group size: {data.groupby(\"treatment\").size().mean()}\\n')\n",
    "\n",
    "# get average size of each group and topic\n",
    "print(f'Average group size by topic: {data.groupby([\"treatment\", \"topic\"]).size().mean()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_subset = data[['user_id', 'treatment', 'age', 'gender', 'education', 'politics']]\n",
    "demographics_subset = demographics_subset.drop_duplicates()\n",
    "\n",
    "# translate education\n",
    "education_dict = {\n",
    "    'Hochschulabschluss': 'University degree',\n",
    "    'Abitur': 'A-levels',\n",
    "    'Realschulabschluss': 'High school',\n",
    "    'Hauptschulabschluss': 'Secondary school',\n",
    "    'Kein Abschluss': 'No degree',\n",
    "    'Keine Angabe': 'No information'\n",
    "}\n",
    "\n",
    "education_dict = {\n",
    "    'Hochschulabschluss': 'University degree',\n",
    "    'Abitur': 'High school diploma',\n",
    "    'Realschulabschluss': 'Intermediate secondary\\n school certificate',\n",
    "    'Hauptschulabschluss': 'Basic secondary\\n school certificate',\n",
    "    'Kein Abschluss': 'No degree',\n",
    "    'Keine Angabe': 'No information'\n",
    "}\n",
    "\n",
    "demographics_subset['education'] = demographics_subset['education'].map(education_dict)\n",
    "\n",
    "# translate political interest\n",
    "politics_dict = {\n",
    "    'Sehr stark': 'Very strong',\n",
    "    'stark': 'Strong',\n",
    "    'mittelmäßig': 'Moderate',\n",
    "    'weniger stark': 'Weak',\n",
    "    'überhaupt nicht': 'Not at all'\n",
    "}\n",
    "\n",
    "demographics_subset['politics'] = demographics_subset['politics'].map(politics_dict)\n",
    "\n",
    "# translate gender\n",
    "gender_dict = {\n",
    "    'Männlich': 'Male',\n",
    "    'Weiblich': 'Female',\n",
    "    'Divers': 'Diverse',\n",
    "    'Keine Angabe': 'No information'\n",
    "}\n",
    "\n",
    "demographics_subset['gender'] = demographics_subset['gender'].map(gender_dict)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(16/2.54, 16/2.54))\n",
    "\n",
    "fontsize = 6\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# Plot Age\n",
    "# order age groups alphabetically\n",
    "demographics_subset['age'] = demographics_subset['age'].astype(str)\n",
    "demographics_subset['age'] = pd.Categorical(demographics_subset['age'], categories=sorted(demographics_subset['age'].unique()))\n",
    "sns.countplot(data=demographics_subset, x='age', ax=axs[0, 0], hue='treatment', palette='Greys')\n",
    "axs[0, 0].set_title('Age', size=fontsize, fontweight='bold')\n",
    "axs[0, 0].set_xlabel('', size=fontsize)\n",
    "axs[0, 0].set_ylabel('Count', size=fontsize)\n",
    "axs[0, 0].get_legend().remove()\n",
    "\n",
    "# Plot Gender\n",
    "demographics_subset['gender'] = pd.Categorical(demographics_subset['gender'], categories=gender_dict.values())\n",
    "sns.countplot(data=demographics_subset, x='gender', ax=axs[0, 1], hue='treatment', palette='Greys')\n",
    "axs[0, 1].set_title('Gender', size=fontsize, fontweight='bold')\n",
    "axs[0, 1].set_xlabel('', size=fontsize)\n",
    "axs[0, 1].set_ylabel('Count', size=fontsize)\n",
    "axs[0, 1].get_legend().remove()\n",
    "\n",
    "# Plot Education\n",
    "demographics_subset['education'] = pd.Categorical(demographics_subset['education'], categories=education_dict.values())\n",
    "demographics_subset = demographics_subset.sort_values('education')\n",
    "sns.countplot(data=demographics_subset, x='education', ax=axs[1, 0], hue='treatment', palette='Greys')\n",
    "axs[1, 0].set_title('Education', size=fontsize, fontweight='bold')\n",
    "axs[1, 0].set_xlabel('', size=fontsize)\n",
    "axs[1, 0].set_ylabel('Count', size=fontsize)\n",
    "axs[1, 0].get_legend().remove()\n",
    "\n",
    "# Plot Politics\n",
    "demographics_subset['politics'] = pd.Categorical(demographics_subset['politics'], categories=politics_dict.values())\n",
    "sns.countplot(data=demographics_subset, x='politics', ax=axs[1, 1], hue='treatment', palette='Greys')\n",
    "axs[1, 1].set_title('Interest in Politics', size=fontsize, fontweight='bold')\n",
    "axs[1, 1].set_xlabel('', size=fontsize)\n",
    "axs[1, 1].set_ylabel('Count', size=fontsize)\n",
    "axs[1, 1].get_legend().remove()\n",
    "\n",
    "# Rotate x-axis labels and set horizontal alignment to right\n",
    "axs[0, 0].tick_params(axis='x', rotation=45, labelsize=fontsize)\n",
    "axs[0, 1].tick_params(axis='x', rotation=45, labelsize=fontsize)\n",
    "axs[1, 0].tick_params(axis='x', rotation=45, labelsize=fontsize)\n",
    "axs[1, 1].tick_params(axis='x', rotation=45, labelsize=fontsize)\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_horizontalalignment('right')\n",
    "\n",
    "\n",
    "# Set size of y-axis labels\n",
    "axs[0, 0].tick_params(axis='y', labelsize=fontsize)\n",
    "axs[0, 1].tick_params(axis='y', labelsize=fontsize)\n",
    "axs[1, 0].tick_params(axis='y', labelsize=fontsize)\n",
    "axs[1, 1].tick_params(axis='y', labelsize=fontsize)\n",
    "\n",
    "# Create a single legend at the bottom\n",
    "handles, labels = axs[0, 0].get_legend_handles_labels()\n",
    "\n",
    "# Capitalize labels\n",
    "labels = [label.capitalize() for label in labels]\n",
    "\n",
    "fig.legend(handles, labels, loc='lower center', ncol=3, title='Treatment', fontsize=fontsize, title_fontsize=fontsize)\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.grid(axis='y', linewidth=0.5)\n",
    "\n",
    "# Addjust linewidth of frames of the subplots\n",
    "for ax in axs.flatten():\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "# Adjust layout and add more space at the bottom\n",
    "plt.subplots_adjust(left=0.075, right=0.95, top=0.975, bottom=0.15)\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save plot\n",
    "fig.savefig('figures/demographics.pdf')\n",
    "\n",
    "# perform chi-squared test \n",
    "\n",
    "# contingency table\n",
    "contingency_table = pd.crosstab(demographics_subset['treatment'], demographics_subset['age'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print('Age')\n",
    "print(f'Chi-squared test: p-value = {p}')\n",
    "\n",
    "contingency_table = pd.crosstab(demographics_subset['treatment'], demographics_subset['gender'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print('Gender')\n",
    "print(f'Chi-squared test: p-value = {p}')\n",
    "\n",
    "contingency_table = pd.crosstab(demographics_subset['treatment'], demographics_subset['education'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print('Education')\n",
    "print(f'Chi-squared test: p-value = {p}')\n",
    "\n",
    "contingency_table = pd.crosstab(demographics_subset['treatment'], demographics_subset['politics'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print('Politics')\n",
    "print(f'Chi-squared test: p-value = {p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Politcal Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_subset = data[['user_id', 'treatment', 'topic_1', 'topic_2', 'topic_3', 'topic_4']]\n",
    "topics_subset = topics_subset.drop_duplicates()\n",
    "\n",
    "# 2x2 grid of countplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16/2.54, 16/2.54))\n",
    "\n",
    "fontsize = 6\n",
    "\n",
    "sns.countplot(ax=axes[0, 0], data=topics_subset, x='topic_1', hue='treatment', palette='Greys')\n",
    "axes[0, 0].set_title('Topic 1: Nuclear Power', size=fontsize, fontweight='bold')\n",
    "axes[0, 0].set_xticklabels(['Disagree', 'Agree'], size=fontsize)\n",
    "axes[0, 0].set_xlabel('', size=fontsize)\n",
    "axes[0, 0].set_ylabel('Count', size=fontsize)\n",
    "axes[0, 0].yaxis.set_tick_params(labelsize=fontsize)\n",
    "axes[0, 0].get_legend().remove()\n",
    "\n",
    "sns.countplot(ax=axes[0, 1], data=topics_subset, x='topic_2', hue='treatment', palette='Greys')\n",
    "axes[0, 1].set_title('Topic 2: Party Ban', size=fontsize, fontweight='bold')\n",
    "axes[0, 1].set_xticklabels(['Disagree', 'Agree'], size=fontsize)\n",
    "axes[0, 1].set_xlabel('', size=fontsize)\n",
    "axes[0, 1].set_ylabel('Count', size=fontsize)\n",
    "axes[0, 1].yaxis.set_tick_params(labelsize=fontsize)\n",
    "axes[0, 1].get_legend().remove()\n",
    "\n",
    "sns.countplot(ax=axes[1, 0], data=topics_subset, x='topic_3', hue='treatment', palette='Greys')\n",
    "axes[1, 0].set_title('Topic 3: Debt Brake', size=fontsize, fontweight='bold')\n",
    "axes[1, 0].set_xticklabels(['Disagree', 'Agree'], size=fontsize)\n",
    "axes[1, 0].set_xlabel('', size=fontsize)\n",
    "axes[1, 0].set_ylabel('Count', size=fontsize)\n",
    "axes[1, 0].yaxis.set_tick_params(labelsize=fontsize)\n",
    "axes[1, 0].get_legend().remove()\n",
    "\n",
    "sns.countplot(ax=axes[1, 1], data=topics_subset, x='topic_4', hue='treatment', palette='Greys')\n",
    "axes[1, 1].set_title('Topic 4: Speed Limit', size=fontsize, fontweight='bold')\n",
    "axes[1, 1].set_xticklabels(['Disagree', 'Agree'], size=fontsize)\n",
    "axes[1, 1].set_xlabel('', size=fontsize)\n",
    "axes[1, 1].set_ylabel('Count', size=fontsize)\n",
    "axes[1, 1].yaxis.set_tick_params(labelsize=fontsize)\n",
    "axes[1, 1].get_legend().remove()\n",
    "\n",
    "# Create a single legend at the bottom\n",
    "handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "\n",
    "# Capitalize labels\n",
    "labels = [label.capitalize() for label in labels]\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.grid(axis='y', linewidth=0.5)\n",
    "\n",
    "# Addjust linewidth of frames of the subplots\n",
    "for ax in axes.flatten():\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "# Adjust layout and add more space at the bottom\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.94])  # Leave space at the bottom\n",
    "plt.subplots_adjust(bottom=0.1)  # Adjust bottom spacing\n",
    "\n",
    "fig.legend(handles, labels, loc='lower center', ncol=3, title='Treatment', fontsize=fontsize, title_fontsize=fontsize)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# save plot as pdf\n",
    "fig.savefig('figures/political_topics.pdf')\n",
    "\n",
    "# chi-squared test for independence\n",
    "\n",
    "# topic 1\n",
    "contingency_table = pd.crosstab(topics_subset['topic_1'], topics_subset['treatment'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f'Chi2: {chi2}, p: {p}')\n",
    "\n",
    "# topic 2\n",
    "contingency_table = pd.crosstab(topics_subset['topic_2'], topics_subset['treatment'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f'Chi2: {chi2}, p: {p}')\n",
    "\n",
    "# topic 3\n",
    "contingency_table = pd.crosstab(topics_subset['topic_3'], topics_subset['treatment'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f'Chi2: {chi2}, p: {p}')\n",
    "\n",
    "# topic 4\n",
    "contingency_table = pd.crosstab(topics_subset['topic_4'], topics_subset['treatment'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f'Chi2: {chi2}, p: {p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Political Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions_subset = data[['user_id', 'treatment', 'dimension_1', 'dimension_2', 'dimension_3', 'dimension_4']]\n",
    "dimensions_subset = dimensions_subset.drop_duplicates()\n",
    "\n",
    "# 2x2 grid of countplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16/2.54, 16/2.54))\n",
    "\n",
    "fontsize = 6\n",
    "\n",
    "sns.countplot(ax=axes[0, 0], data=dimensions_subset, x='dimension_1', hue='treatment', palette='Greys')\n",
    "axes[0, 0].set_title('Dimension 1: Economic Liberalism vs. Welfare State', size=fontsize, fontweight='bold')\n",
    "axes[0, 0].set_xticklabels([int(x + 1) for x in axes[0, 0].get_xticks()], size=fontsize)\n",
    "axes[0, 0].set_xlabel('1 = Prioritize Lower Taxes, 5 = Neutral, 9 = Prioritize Higher Welfare Spending', size=fontsize)\n",
    "axes[0, 0].set_ylabel('Count', size=fontsize)\n",
    "axes[0, 0].yaxis.set_tick_params(labelsize=fontsize)\n",
    "axes[0, 0].get_legend().remove()\n",
    "\n",
    "sns.countplot(ax=axes[0, 1], data=dimensions_subset, x='dimension_2', hue='treatment', palette='Greys')\n",
    "axes[0, 1].set_title('Dimension 2: Social Liberalism vs. Conservatism', size=fontsize, fontweight='bold')\n",
    "axes[0, 1].set_xticklabels([int(x + 1) for x in axes[0, 1].get_xticks()], size=fontsize)\n",
    "axes[0, 1].set_xlabel('1 = Prioritize Individual Freedom, 5 = Neutral, 9 = Prioritize Traditional Values', size=fontsize)\n",
    "axes[0, 1].set_ylabel('Count', size=fontsize)\n",
    "axes[0, 1].yaxis.set_tick_params(labelsize=fontsize)\n",
    "axes[0, 1].get_legend().remove()\n",
    "\n",
    "sns.countplot(ax=axes[1, 0], data=dimensions_subset, x='dimension_3', hue='treatment', palette='Greys')\n",
    "axes[1, 0].set_title('Dimension 3: Climate Protection vs. Standard of Living', size=fontsize, fontweight='bold')\n",
    "axes[1, 0].set_xticklabels([int(x + 1) for x in axes[1, 0].get_xticks()], size=fontsize)\n",
    "axes[1, 0].set_xlabel('1 = Prioritize Climate Protection, 5 = Neutral, 9 = Prioritize Standard of Living', size=fontsize)\n",
    "axes[1, 0].set_ylabel('Count', size=fontsize)\n",
    "axes[1, 0].yaxis.set_tick_params(labelsize=fontsize)\n",
    "axes[1, 0].get_legend().remove()\n",
    "\n",
    "sns.countplot(ax=axes[1, 1], data=dimensions_subset, x='dimension_4', hue='treatment', palette='Greys')\n",
    "axes[1, 1].set_title('Dimension 4: Internationalism vs. Nationalism', size=fontsize, fontweight='bold')\n",
    "axes[1, 1].set_xticklabels([int(x + 1) for x in axes[1, 1].get_xticks()], size=fontsize)\n",
    "axes[1, 1].set_xlabel('1 = Prioritize International Cooperation, 5 = Neutral, 9 = Prioritize National Interests', size=fontsize)\n",
    "axes[1, 1].set_ylabel('Count', size=fontsize)\n",
    "axes[1, 1].yaxis.set_tick_params(labelsize=fontsize)\n",
    "axes[1, 1].get_legend().remove()\n",
    "\n",
    "# Create a single legend at the bottom\n",
    "handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "\n",
    "# Capitalize labels\n",
    "labels = [label.capitalize() for label in labels]\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.grid(axis='y', linewidth=0.5)\n",
    "\n",
    "# Addjust linewidth of frames of the subplots\n",
    "for ax in axes.flatten():\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "# Adjust layout and add more space at the bottom\n",
    "plt.subplots_adjust(left=0.075, right=0.95, top=0.975, bottom=0.125)\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "\n",
    "fig.legend(handles, labels, loc='lower center', ncol=3, title='Treatment', fontsize=fontsize, title_fontsize=fontsize)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# save plot as pdf\n",
    "fig.savefig('figures/political_dimensions.pdf')\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "\n",
    "# Dimension 1\n",
    "f_stat, p_value = stats.f_oneway(dimensions_subset[dimensions_subset['treatment'] == 'targeted']['dimension_1'],\n",
    "                                 dimensions_subset[dimensions_subset['treatment'] == 'non-targeted']['dimension_1'],\n",
    "                                 dimensions_subset[dimensions_subset['treatment'] == 'false-targeted']['dimension_1'])\n",
    "\n",
    "# Output the results\n",
    "print(\"One-way ANOVA: Dimension 1\")\n",
    "print(f\"F-Statistic: {f_stat}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "print()\n",
    "\n",
    "# Dimension 2\n",
    "f_stat, p_value = stats.f_oneway(dimensions_subset[dimensions_subset['treatment'] == 'targeted']['dimension_2'],\n",
    "                                 dimensions_subset[dimensions_subset['treatment'] == 'non-targeted']['dimension_2'],\n",
    "                                 dimensions_subset[dimensions_subset['treatment'] == 'false-targeted']['dimension_2'])\n",
    "\n",
    "# Output the results\n",
    "print(\"One-way ANOVA: Dimension 2\")\n",
    "print(f\"F-Statistic: {f_stat}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "print()\n",
    "\n",
    "# Dimension 3\n",
    "f_stat, p_value = stats.f_oneway(dimensions_subset[dimensions_subset['treatment'] == 'targeted']['dimension_3'],\n",
    "                                 dimensions_subset[dimensions_subset['treatment'] == 'non-targeted']['dimension_3'],\n",
    "                                 dimensions_subset[dimensions_subset['treatment'] == 'false-targeted']['dimension_3'])\n",
    "\n",
    "# Output the results\n",
    "print(\"One-way ANOVA: Dimension 3\")\n",
    "print(f\"F-Statistic: {f_stat}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "print()\n",
    "\n",
    "# Dimension 4\n",
    "\n",
    "f_stat, p_value = stats.f_oneway(dimensions_subset[dimensions_subset['treatment'] == 'targeted']['dimension_4'],\n",
    "                                 dimensions_subset[dimensions_subset['treatment'] == 'non-targeted']['dimension_4'],\n",
    "                                 dimensions_subset[dimensions_subset['treatment'] == 'false-targeted']['dimension_4'])\n",
    "\n",
    "# Output the results\n",
    "print(\"One-way ANOVA: Dimension 4\")\n",
    "print(f\"F-Statistic: {f_stat}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "print()\n",
    "\n",
    "# chi-squared test for independence\n",
    "\n",
    "# dimension 1\n",
    "contingency_table = pd.crosstab(dimensions_subset['dimension_1'], dimensions_subset['treatment'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print('Chi-squared test for independence: Dimension 1')\n",
    "print(f'Chi2: {chi2}, p: {p}')\n",
    "print()\n",
    "\n",
    "# dimension 2\n",
    "contingency_table = pd.crosstab(dimensions_subset['dimension_2'], dimensions_subset['treatment'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print('Chi-squared test for independence: Dimension 2')\n",
    "print(f'Chi2: {chi2}, p: {p}')\n",
    "print()\n",
    "\n",
    "# dimension 3\n",
    "contingency_table = pd.crosstab(dimensions_subset['dimension_3'], dimensions_subset['treatment'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print('Chi-squared test for independence: Dimension 3')\n",
    "print(f'Chi2: {chi2}, p: {p}')\n",
    "print()\n",
    "\n",
    "# dimension 4\n",
    "contingency_table = pd.crosstab(dimensions_subset['dimension_4'], dimensions_subset['treatment'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print('Chi-squared test for independence: Dimension 4')\n",
    "print(f'Chi2: {chi2}, p: {p}')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceived Audience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16/2.54, 8/2.54))  # Increase the figure size to give more space\n",
    "\n",
    "# Updated color palette for better contrast between groups\n",
    "sns.countplot(data=data, x='post_treatment_1', hue='treatment', stat='proportion', palette='Greys')\n",
    "\n",
    "# Print means of post_treatment_1 by treatment (optional for debugging purposes)\n",
    "print(data.groupby(['treatment'])['post_treatment_1'].mean())\n",
    "\n",
    "# Update legend for better readability\n",
    "plt.legend(title='Treatment Group',\n",
    "           loc='upper left',\n",
    "           labels=['Targeted', 'False-Targeted', 'Non-Targeted'],\n",
    "           fontsize=8,\n",
    "           title_fontsize=8).get_frame().set_linewidth(0.5)\n",
    "\n",
    "# Update x-tick labels with shorter text and rotate them 45 degrees for better readability\n",
    "plt.xticks(\n",
    "    [0, 1, 2, 3, 4, 5, 6, 7, 8], \n",
    "    [\n",
    "        '1. Very similar', '2.', '3.', '4.', '5. General audience', \n",
    "        '6.', '7.', '8.', '9. Very different'\n",
    "    ], \n",
    "    rotation=0, ha='center', size=8\n",
    ")\n",
    "\n",
    "plt.yticks(size=8)\n",
    "\n",
    "# Set labels for the axes\n",
    "plt.xlabel('Perceived Audience of Message', size=8)\n",
    "plt.ylabel('Proportion', size=8)\n",
    "\n",
    "# Add horizontal gridlines for better comparison\n",
    "plt.grid(axis='y', linestyle='-', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "# Get the current axes\n",
    "ax = plt.gca()\n",
    "\n",
    "# Set the linewidth for all sides of the frame\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(1)\n",
    "\n",
    "# Show and save the plot\n",
    "plt.tight_layout()  # Ensure everything fits nicely\n",
    "plt.show()\n",
    "\n",
    "# Save the figure as a PDF\n",
    "fig.savefig('figures/perceived_audience.pdf')\n",
    "\n",
    "targeted = data[data['treatment'] == 'targeted']\n",
    "non_targeted = data[data['treatment'] == 'non-targeted']\n",
    "false_targeted = data[data['treatment'] == 'false-targeted']\n",
    "\n",
    "# Perform the Chi-Square test\n",
    "chi2, p, dof, expected = chi2_contingency([targeted['post_treatment_1'].value_counts(), non_targeted['post_treatment_1'].value_counts(), false_targeted['post_treatment_1'].value_counts()])\n",
    "\n",
    "# Output the results\n",
    "print(f\"Chi2 Statistic: {chi2}\")\n",
    "print(f\"P-Value: {p}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_messaging_strategies_by_topic(data, \n",
    "                                   'treatment_var_1', \n",
    "                                   ['False-Targeted', 'Non-Targeted', 'Targeted'],\n",
    "                                   topics_dict,\n",
    "                                   calculate_confidence_interval, \n",
    "                                   'Estimate of Persuasive Impact (95% CI)', \n",
    "                                   'figures/messaging_strategies_by_topic.pdf', \n",
    "                                   x_limits=(1, 4.25), \n",
    "                                   colors=colors,\n",
    "                                   markers=markers)\n",
    "\n",
    "targeted = data[data['treatment'] == 'targeted']['treatment_var_1']\n",
    "non_targeted = data[data['treatment'] == 'non-targeted']['treatment_var_1']\n",
    "false_targeted = data[data['treatment'] == 'false-targeted']['treatment_var_1']\n",
    "\n",
    "print(f\"Targeted vs. Non-Targeted: {targeted.mean():.2f} vs. {non_targeted.mean():.2f}, p-value = {st.ttest_ind(targeted, non_targeted, equal_var=False).pvalue / 2:.4f}\")\n",
    "print(f\"Targeted vs. False-Targeted: {targeted.mean():.2f} vs. {false_targeted.mean():.2f}, p-value = {st.ttest_ind(targeted, false_targeted, equal_var=False).pvalue / 2:.4f}\")\n",
    "print(f\"Non-Targeted vs. False-Targeted: {non_targeted.mean():.2f} vs. {false_targeted.mean():.2f}, p-value = {st.ttest_ind(non_targeted, false_targeted, equal_var=False).pvalue / 2:.4f}\")\n",
    "print(\"\")\n",
    "\n",
    "for topic in data['topic'].unique():\n",
    "    targeted = data[(data['treatment'] == 'targeted') & (data['topic'] == topic)]['treatment_var_1']\n",
    "    non_targeted = data[(data['treatment'] == 'non-targeted') & (data['topic'] == topic)]['treatment_var_1']\n",
    "    false_targeted = data[(data['treatment'] == 'false-targeted') & (data['topic'] == topic)]['treatment_var_1']\n",
    "\n",
    "    print(f\"Targeted vs. Non-Targeted ({topic}): p-value = {st.ttest_ind(targeted, non_targeted, equal_var=False).pvalue / 2:.4f}\")\n",
    "    print(f\"Targeted vs. False-Targeted ({topic}): p-value = {st.ttest_ind(targeted, false_targeted, equal_var=False).pvalue / 2:.4f}\")\n",
    "    print(f\"Non-Targeted vs. False-Targeted ({topic}): p-value = {st.ttest_ind(non_targeted, false_targeted, equal_var=False).pvalue / 2:.4f}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_messaging_strategies_by_topic(data,\n",
    "                                   'treatment_var_2',\n",
    "                                   ['False-Targeted', 'Non-Targeted', 'Targeted'],\n",
    "                                   topics_dict, calculate_confidence_interval,\n",
    "                                   'Perceived Quality of Messages (95% CI)',\n",
    "                                   'figures/quality_of_messaging_strategies_by_topic.pdf',\n",
    "                                   x_limits=(1, 6.5))\n",
    "\n",
    "# perform t-test for each topic\n",
    "topics_dict = {\n",
    "    'Atomkraft': 'nuclear power',\n",
    "    'Parteiverbot': 'party ban',\n",
    "    'Schuldenbremse': 'debt brake',\n",
    "    'Tempolimit': 'general speed limit'\n",
    "}\n",
    "\n",
    "# overall t-test\n",
    "targeted = data[data['treatment'] == 'targeted']['treatment_var_2']\n",
    "non_targeted = data[data['treatment'] == 'non-targeted']['treatment_var_2']\n",
    "false_targeted = data[data['treatment'] == 'false-targeted']['treatment_var_2']\n",
    "\n",
    "print(f\"Targeted vs. Non-Targeted (overall: {targeted.mean():.2f} vs. {non_targeted.mean():.2f}, p = {st.ttest_ind(targeted, non_targeted, equal_var=False).pvalue / 2:.4f})\")\n",
    "print(f\"Targeted vs. False-Targeted (overall: {targeted.mean():.2f} vs. {false_targeted.mean():.2f}, p = {st.ttest_ind(targeted, false_targeted, equal_var=False).pvalue / 2:.4f})\")\n",
    "print(f\"Non-Targeted vs. False-Targeted (overall: {non_targeted.mean():.2f} vs. {false_targeted.mean():.2f}, p = {st.ttest_ind(non_targeted, false_targeted, equal_var=False).pvalue / 2:.4f}\")\n",
    "print(\"\")\n",
    "\n",
    "for topic in data['topic'].unique():\n",
    "    targeted = data[(data['treatment'] == 'targeted') & (data['topic'] == topic)]['treatment_var_2']\n",
    "    non_targeted = data[(data['treatment'] == 'non-targeted') & (data['topic'] == topic)]['treatment_var_2']\n",
    "    false_targeted = data[(data['treatment'] == 'false-targeted') & (data['topic'] == topic)]['treatment_var_2']\n",
    "\n",
    "    print(f\"Targeted vs. Non-Targeted ({topics_dict[topic]}: {targeted.mean():.2f} vs. {non_targeted.mean():.2f}, p = {st.ttest_ind(targeted, non_targeted, equal_var=False).pvalue / 2:.4f})\")\n",
    "    print(f\"Targeted vs. False-Targeted ({topics_dict[topic]}: {targeted.mean():.2f} vs. {false_targeted.mean():.2f}, p = {st.ttest_ind(targeted, false_targeted, equal_var=False).pvalue / 2:.4f})\")\n",
    "    print(f\"Non-Targeted vs. False-Targeted ({topics_dict[topic]}: {non_targeted.mean():.2f} vs. {false_targeted.mean():.2f}, p = {st.ttest_ind(non_targeted, false_targeted, equal_var=False).pvalue / 2:.4f})\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of words in argument\n",
    "data['argument_length'] = data['argument'].str.split().apply(len)\n",
    "\n",
    "plot_messaging_strategies_by_topic(data,\n",
    "                                   'argument_length',\n",
    "                                   ['False-Targeted', 'Non-Targeted', 'Targeted'],\n",
    "                                   topics_dict, calculate_confidence_interval,\n",
    "                                   'Argument Length in Words (95% CI)', 'figures/argument_length_by_topic.pdf',\n",
    "                                   x_limits=(100, 150))\n",
    "\n",
    "# perform t-test for argument length\n",
    "\n",
    "targeted = data[data['treatment'] == 'targeted']['argument_length']\n",
    "non_targeted = data[data['treatment'] == 'non-targeted']['argument_length']\n",
    "false_targeted = data[data['treatment'] == 'false-targeted']['argument_length']\n",
    "\n",
    "print(f\"Targeted vs. Non-Targeted (overall: {targeted.mean():.2f} vs. {non_targeted.mean():.2f}, p = {st.ttest_ind(targeted, non_targeted, equal_var=False).pvalue / 2:.4f})\")\n",
    "print(f\"Targeted vs. False-Targeted (overall: {targeted.mean():.2f} vs. {false_targeted.mean():.2f}, p = {st.ttest_ind(targeted, false_targeted, equal_var=False).pvalue / 2:.4f}\")\n",
    "print(f\"Non-Targeted vs. False-Targeted (overall: {non_targeted.mean():.2f} vs. {false_targeted.mean():.2f}, p = {st.ttest_ind(non_targeted, false_targeted, equal_var=False).pvalue / 2:.4f}\")\n",
    "print(\"\")\n",
    "\n",
    "for topic in data['topic'].unique():\n",
    "    targeted = data[(data['treatment'] == 'targeted') & (data['topic'] == topic)]['argument_length']\n",
    "    non_targeted = data[(data['treatment'] == 'non-targeted') & (data['topic'] == topic)]['argument_length']\n",
    "    false_targeted = data[(data['treatment'] == 'false-targeted') & (data['topic'] == topic)]['argument_length']\n",
    "\n",
    "    print(f\"Targeted vs. Non-Targeted ({topics_dict[topic]}: {targeted.mean():.2f} vs. {non_targeted.mean():.2f}, p = {st.ttest_ind(targeted, non_targeted, equal_var=False).pvalue / 2:.4f})\")\n",
    "    print(f\"Targeted vs. False-Targeted ({topics_dict[topic]}: {targeted.mean():.2f} vs. {false_targeted.mean():.2f}, p = {st.ttest_ind(targeted, false_targeted, equal_var=False).pvalue / 2:.4f})\")\n",
    "    print(f\"Non-Targeted vs. False-Targeted ({topics_dict[topic]}: {non_targeted.mean():.2f} vs. {false_targeted.mean():.2f}, p = {st.ttest_ind(non_targeted, false_targeted, equal_var=False).pvalue / 2:.4f}\")\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
